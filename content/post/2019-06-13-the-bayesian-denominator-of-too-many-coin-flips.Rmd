---
title: The Bayesian denominator of too many coin flips
author: Pedro Pinto da Silva
date: '2019-06-19'
slug: the-bayesian-denominator-of-too-many-coin-flips
categories: ['stats']
tags: ['stats-101', 'book-lambert', 'lambert-chapter-6']
draft: true
output:
  blogdown::html_page:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache =TRUE)
library(tidyverse)
library(gganimate)
library(kableExtra)
library(formattable)

theme_color = "#5D8AA8"
```

# The problem

Today we look at problem 6.1 _Too many coin flips_, from Ben Lambert's book _A Student's Guide to Bayesian Statistics_.

We continue working with coins.

This time around we have 2 coins, whose nature we are unsure about (probability of heads). However, we know that each coin $i$ can be fair ($\theta_i = 0.5$) or biased towards heads ($\theta_i = 0.9$).

# A uniform start

Suppose that:

- we flip each coin twice: $n = 2$
- we place a discrete uniform prior on the coin's identity $i$

**Q:** What is the joint distribution of the data and the coins' identity?

First things first, let $X_i$ be the number of heads in $n$ throws of coin $i$. Then the joint distribution of interest is:

$$
Pr(X_1, X_2, \theta_1, \theta_2) = Pr(X_{1:2}, \theta_{1:2})
$$

If we assume that the two coin throws are independent (i.e. the outcome of throwing coin 1 does not affect the outcome throwing coin 2), then:

$$
Pr(X_{1:2}, \theta_{1:2}) = \prod_{i = 1}^{2} Pr(X_i, \theta_i) = \prod_{i = 1}^{2} Pr(X_i \mid \theta_i) \times Pr(\theta_i)
$$


Note that, for each coin, we can write the joint ($Pr(X_i, \theta_i)$) as the product of the conditional distribution of the data given the parameters $Pr(X_i \mid \theta_i)$ and the distribution of the coin's identity ($Pr(\theta_i)$). Therefore, if we know how to calculate these two terms, then we can easily compute the whole thing:

- the binomial distribution is an adequate probability distribution to model the outcome of $n$ independent coin flips (we've seen in a [previous post](/2019/06/05/bayesian-priors-and-dodgy-coins/)), given the coins identity:

$$
Pr(x_i \mid \theta_i) = \binom{n}{x_i} \theta_{i}^{x_i}(1-\theta_{i})^{n-x_i}
$$


- the uniform assumption over the coin's identity tells us how to calculate $Pr(\theta_i)$:

$$
\begin{align}
Pr(\theta_i = 1) = 1/2 , \quad Pr(\theta_i = 2) = 1/2\\
\end{align}
$$


```{r joint, echo = FALSE, eval = FALSE}
coins_tibble <- function(n, theta) {
  ncoins <- length(theta)
  
  comb <- expand.grid(rep(list(theta = theta, x = 0:ncoins), ncoins))
  column_names <- paste0(c("theta_", "x_"), sapply(1:ncoins, function(i) rep(i, ncoins)))
  colnames(comb) <- column_names
  
  comb <-
    comb %>%
    as_tibble() %>%
    rowid_to_column(var = "case")
  
  comb_theta <- 
    comb %>%
    gather(paste0("theta_", 1:ncoins), key = "theta_i", value = "theta") %>%
    separate(theta_i, c("dummy","i"), "_") %>%
    mutate(i = as.numeric(i)) %>%
    select(-c(paste0("x_", 1:ncoins), dummy))
  
  comb_x <- 
    comb %>%
    gather(paste0("x_", 1:ncoins), key = "x_i", value = "x") %>%
    separate(x_i, c("dummy","i"), "_") %>%
    mutate(i = as.numeric(i)) %>%
    select(-c(paste0("theta_", 1:ncoins), dummy))
  
  list(
    comb = comb,
    df   = 
      inner_join(comb_theta, comb_x, by = c("case", "i")) %>%
      mutate(n = n)
  )
}

prior <- c(1/2, 1/2)

l = coins_tibble(2, c(0.5, 0.9))

l_joint <-
  l$df %>%
  mutate(prior = prior[i]) %>%
  mutate(p = dbinom(x, n, theta) * prior) %>%
  group_by(case) %>%
  summarise(joint_p = prod(p)) %>%
  inner_join(l$comb, by = "case")

l_joint

 l_joint %>%
  summarise(sum(joint_p))
```

And a little code to do the computation for us:

```{r joint dist}
joint <- 
  tibble(
    x1     = c(0, 1, 2),
    x2     = c(0, 1, 2),
    theta1 = c(0.5, 0.9, 0.5),
    theta2 = c(0.5, 0.9, 0.5)
  ) %>%
  expand(x1, x2, theta1, theta2) %>%
  mutate(
    n     = 2,
    prior1 = 1/2,
    prior2 = 1/2
  ) %>%
  mutate(
    p1 = dbinom(x1, n, theta1) * prior1,
    p2 = dbinom(x2, n, theta2) * prior2
  ) %>%
  mutate(p = p1 * p2)

```

```{r joint table, echo = FALSE}
joint %>%
  select(-c(n, prior1, prior2, p1, p2)) %>%
  knitr::kable(escape = FALSE)
  # print(n = 36)
  # pull(p) %>%
  # matrix(
  #   nrow = 3^2,
  #   ncol = 2^2,
  #   dimnames = list(
  #     joint %>% unite("x1_x2", )
  #   )) %>%
  # knitr::kable(escape = FALSE)
```

We can verify that the above distribution is a valid probability distribution:

```{r verify valid dist}
joint %>%
  summarise(sum(p))
```

# One likelihood to rule them all

